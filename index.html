<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ziming Li</title>

    <meta name="author" content="Ziming Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/Naruto.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel='stylesheet' href='https://chinese-fonts-cdn.deno.dev/packages/xuandongkaishu/dist/XuandongKaishu/result.css' />
    
  </head>

  <body>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom: 30px"><tbody>
      <tr style="padding:0px">
        <td class="fixed-header" style="font-size: larger">
          <a href="https://dravenalg.github.io" style="padding-right: 150px; font-size: large;" class="header_name"><img src="images/Naruto.png" style="width: 20px"> Ziming Li</a>
          <a href="#bio" style="padding-right: 30px;padding-left: 30px" class="header_navi">Bio</a>
          <a href="#publication" style="padding-right: 30px;padding-left: 30px" class="header_navi">Publications</a>
          <!-- <a href="#service" style="padding-right: 30px;padding-left: 30px" class="header_navi">Services</a> -->
          <!-- <a href="#award" style="padding-right: 30px;padding-left: 30px" class="header_navi">Awards</a> -->
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td class="personal_image" style="padding:2.5%; width:40%;max-width:40%">
                <img style="width:70%;max-width:100%;object-fit: cover;border-radius: 200px" alt="profile photo" src="images/myself.jpg" class="personal_img">
              </td>

              <td style="width:63%;vertical-align:middle">
                <p class="name" style="text-align: left;">
                  Ziming Li <span style="padding-left: 5px" class="chinese_name">李梓铭</span>
                </p>
                <p>
                  M.S. student
                </p>
                <p>
                  College of Computer Science and Electronic Engineering
                </p>
                <p>
                  Hunan University
                </p>
                <p>
                  Email: zimingli@hnu.edu.cn
                </p>
                <p style="text-align:left">
                  <!-- <a href="https://scholar.google.com/citations?hl=zh-CN&user=Li7oZpsAAAAJ" target="_blank">
                    [<span style="color: #4285F4; margin-right: -2px">G</span>
                    <span style="color: #EA4335; margin-right: -2px">o</span>
                    <span style="color: #FBBC05; margin-right: -2px">o</span>
                    <span style="color: #4285F4; margin-right: -2px">g</span>
                    <span style="color: #34A853; margin-right: -2px">l</span>
                    <span style="color: #EA4335; margin-right: -2px">e</span> &nbsp Scholar]</a> &nbsp;&nbsp; -->
                  <a href="https://github.com/zmli6" target="_blank"><strong style="color: black">[GitHub]</strong></a>
                </p>
              </td>

            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td style="width:100%; vertical-align:middle">
                <h2 id="bio" style="scroll-margin-top: 45px;">
                  Biography
                </h2>
                <p>
                  I'm currently a third-year master student at <a href="https://www.hnu.edu.cn/" target="_blank">Hunan university</a>, advised by Prof. <a href="https://csee.hnu.edu.cn/people/liyouhuan" target="_blank">Youhuan Li</a>, where I develop the scientific ability and a good taste of it.
                  I will be joining the <a href="https://chuxuzhang.github.io/Lab/lab_index.html" target="_blank">Machine Intelligence and Data Science Lab</a> at the <a href="https://uconn.edu/" target="_blank">University of Connecticut</a> in the fall of 2025, under the supervision of Prof. <a href="https://csee.hnu.edu.cn/people/liyouhuan" target="_blank">Chuxu Zhang</a>.
                </p>

                <!-- <p>
                  <em class="ref">
                    Research is for curiosity and fun.
                  </em>
                </p> -->

                <!-- <p>
                  I am interested in general deep learning topics, including algorithms, theories, systems and its applications on vision, language scenarios.
                  My long-term goal is to build a strong, efficient (reach human-level), and safe (surpass human level) AI agent.
                  Now I am mainly focusing on embodied AI algorithms. Previously, I also conducted research on efficient AI algorithms.
                </p> -->
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
          <tr>
            <td style="width:100%; vertical-align:middle">
              <h2>
                News
              </h2>
              <div class="scrollable" style="max-height:130px; overflow-y:scroll; padding-right:10px; margin-top: 10px; margin-bottom: 10px">
                <p>
                  <span style="font-size: smaller">➤</span> [2024-08] One paper accepted in WSDM 2024.
                </p>
                <p>
                  <span style="font-size: smaller">➤</span> [2024-03] One paper accepted in ICDE 2024.
                </p>
              </div>
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 0px; margin-bottom: -10px;"><tbody>
            <tr>
              <td style="width:80%; vertical-align:middle">
                <h2 id="publication" style="scroll-margin-top: 45px;">Selected Publications</h2>
                <p>
                  Below are my selected publications.
                  <!-- (& means equal contribution, * refers to corresponding author.) -->
                </p>
              </td>
            </tr>
           </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/RSM.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="" target="_blank">
                  <span class="papertitle">RSM: Reinforced Subgraph Matching Framework with Fine-grained Operation based Search Plan</span>
                </a>
                <br>
                <strong>Ziming Li</strong>, Yuequn Dou, Youhuan Li, Xinhuan Chen, Chuxu Zhang.
                <br>
                <em>International Conference on Web Search and Data Mining (WSDM)</em>, 2024.
                <br>
                <a href="" target="_blank">paper</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(RSM)</strong> We propose a new search framework in machine learning subgraph matching and employ reinforced learning and gnn to generate search plan.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/newsp.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/document/10597892" target="_blank">
                  <span class="papertitle">NewSP: A New Search Process for Continuous Subgraph Matching over Dynamic Graphs</span>
                </a>
                <br>
                <strong>Ziming Li</strong>, Youhuan Li, Xinhuan Chen, Lei Zou, Xiaofeng Yang, Yang Li, Hongbo Jiang.
                <br>
                <em>International Conference on Data Engineering (ICDE)</em>, 2024.
                <br>
                <a href="https://github.com/hnuGraph/NewSP" target="_blank">code</a>
                /
                <a href="https://ieeexplore.ieee.org/document/10597892" target="_blank">paper</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(NEWSP)</strong> We propose a new search process in Continuous Subgraph Matching(CSM) problem with multi-expand, cache reuse and adaptive check strategies.
                </p>
              </td>
            </tr>
            <tr>

              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/vend.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/document/10184618" target="_blank">
                  <span class="papertitle">VEND: Vertex Encoding for Edge Nonexistence Determination</span>
                </a>
                <br>
                Youhuan Li, Hangyu Zheng, Lei Zou, Xiaosen Li, <strong>Ziming Li</strong>, Pin Xiao, Yangyu Tao, Zheng Qin.
                <br>
                <em>International Conference on Data Engineering (ICDE)</em>, 2023.
                <br>
                <a href="https://github.com/hnuGraph/VEND" target="_blank">code</a>
                /
                <a href="https://ieeexplore.ieee.org/document/10184618" target="_blank">paper</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(VEND)</strong> We propose to design vertex encoding for determinations of no-result edge queries that should not be executed.
                </p>
              </td>
            </tr>

            <!-- <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/PixelFade.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://arxiv.org/abs/2408.05543" target="_blank">
                  <span class="papertitle">PixelFade: Privacy-preserving Person Re-identification with Noise-guided Progressive Replacement</span>
                </a>
                <br>
                Delong Zhang, Yi-Xing Peng, <strong>Xiao-Ming Wu</strong>, Ancong Wu*, Wei-Shi Zheng.
                <br>
                <em>ACM Multimedia (MM)</em>, 2024.
                <br>
                <a href="https://arxiv.org/abs/2408.05543" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/PixelFade" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Privacy Protection)</strong> We propose a two-step iterative method (PixelFade) for person privacy-preserving, with the partial replacement step to turn image into noise to resist recovery attack, and the constrain operation step to maintain Re-id semantics.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/EconomicGrasp.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://arxiv.org/abs/2407.08366" target="_blank">
                  <span class="papertitle">An Economic Framework for 6-DoF Grasp Detection</span>
                </a>
                <br>
                <strong>Xiao-Ming Wu&</strong>, Jia-Feng Cai&, Jian-Jian Jiang, Dian Zheng, Yi-Lin Wei, Wei-Shi Zheng*
                <br>
                <em>European Conference on Computer Vision (ECCV)</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2407.08366" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/EconomicGrasp" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(6-DoF Grasp)</strong> We propose a new economic grasping framework for 6-DoF grasp detection to economize the training resource cost and meanwhile maintain effective grasp performance.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/DiffUIR.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Selective_Hourglass_Mapping_for_Universal_Image_Restoration_Based_on_Diffusion_CVPR_2024_paper.html" target="_blank">
                  <span class="papertitle">Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model</span>
                </a>
                <br>
                Dian Zheng, <strong>Xiao-Ming Wu</strong>, Shuzhou Yang, Jian Zhang, Jian-Fang Hu, Wei-Shi Zheng*
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2024.
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Selective_Hourglass_Mapping_for_Universal_Image_Restoration_Based_on_Diffusion_CVPR_2024_paper.html" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/DiffUIR" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Image Restoration)</strong> We propose a diffusion-based universal image restoration model, with an assemble-then-separate (like the hourglass) mapping for multi-task training, to learn the shared information between different tasks.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/ReSTE.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html" target="_blank">
                  <span class="papertitle">Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training</span>
                </a>
                <br>
                <strong>Xiao-Ming Wu</strong>, Dian Zheng, Zuhao Liu, Wei-Shi Zheng*
                <br>
                <em>International Conference on Computer Vision (ICCV)</em>, 2023
                <br>
                <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html" target="_blank">paper</a>
                /
                <a href="https://github.com/DravenALG/ReSTE" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Binary Neural Networks)</strong> We propose a new perspective to view the binary neural network training: equilibrium between estimating error and gradient stability, and design a simple and effective gradient estimator (ReSTE) to balance it well.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/DOCH.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://www.sciencedirect.com/science/article/pii/S0031320321004428" target="_blank">
                  <span class="papertitle">Discrete Online Cross-modal Hashing</span>
                </a>
                <br>
                Yu-Wei Zhan, Yongxin Wang, Yu Sun, <strong>Xiao-Ming Wu</strong>, Xin Luo*, Xin-Shun Xu
                <br>
                <em>Pattern Recognition (PR)</em>, 2022
                <br>
                <a href="https://www.sciencedirect.com/science/article/pii/S0031320321004428" target="_blank">paper</a>
                /
                <a href="https://github.com/yw-zhan/DOCH" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Hashing Retrieval)</strong> We propose a novel cross-modal online hashing method, directly exploiting the similarity between newly coming data and old existing data in the Hamming space to learn discriminate hashing codes.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/OASIS.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20346" target="_blank">
                  <span class="papertitle">Online Enhanced Semantic Hashing Towards Effective and Efficient Retrieval for Streaming Multi-Modal Data</span>
                </a>
                <br>
                <strong>Xiao-Ming Wu</strong>, Xin Luo*, Yu-Wei Zhan, Chen-Lu Ding, Zhen-Duo Chen, Xin-Shun Xu
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022
                <br>
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20346" target="_blank">paper</a>
                /
                <a href="https://github.com/DravenALG/OASIS" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Hashing Retrieval)</strong> We explore a new task, incremental multi-modal hashing, and introduce semantics to solve this task, handling the dimension mismatching problem and mitigating the inconsistent problem that occurs when new classes come.
                </p>
              </td>
            </tr> -->


          <!-- </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
          <tr>
            <td style="width:100%; vertical-align:middle">
              <h2 id="service" style="scroll-margin-top: 45px;">
                Services and Activities
              </h2>
              <p>
                Journal Reviewer: Pattern Analysis and Machine Intelligence (TPAMI), Pattern Recognition (PR).
              </p>
              <p>
                Conference Reviewer: Computer Vision and Pattern Recognition (CVPR) 2024, ACM Multimedia (MM) 2024.
              </p>
            </td>
          </tr>

          </tbody></table> -->
<!-- 
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
          <tr>
            <td style="width:100%; vertical-align:middle">
              <h2 id="award" style="scroll-margin-top: 45px;">
                Selected Awards
              </h2>
              <p>

              <div style="padding-bottom: 5px"> First Prize, Academic Scholarship of Sun Yat-Sen University (中山大学学业一等奖学金), 2022, 2023, 2024. </div>
              <div style="padding-bottom: 5px"> National Scholarship of China for Graduate Student (研究生国家奖学金), 2023. </div>
                <div style="padding-bottom: 5px"> Honorable Bachelor Degree of Shandong University (山东大学荣誉学士学位), 2022. </div>
                <div style="padding-bottom: 5px"> National Scholarship of China for Undergraduate Student  (本科生国家奖学金), 2019, 2021. </div>
                <div style="padding-bottom: 5px"> First Prize, Academic Scholarship of Shandong University (山东大学学业一等奖学金), 2019, 2020, 2021. </div>
              </p>
            </td>
          </tr>
          </tbody></table> -->

        </td>
      </tr>
    </table>

    <script src="script.js"></script>

  </body>
</html>
